--- drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -1896,20 +1896,14 @@ static int axienet_probe(struct platform_device *pdev)
 
 	/* Find the DMA node, map the DMA registers, and decode the DMA IRQs */
 	np = of_parse_phandle(pdev->dev.of_node, "axistream-connected", 0);
-	if (np) {
-		struct resource dmares;
-
-		ret = of_address_to_resource(np, 0, &dmares);
-		if (ret) {
-			dev_err(&pdev->dev,
-				"unable to get DMA resource\n");
-			of_node_put(np);
-			goto free_netdev;
-		}
-		lp->dma_regs = devm_ioremap_resource(&pdev->dev,
-						     &dmares);
-		lp->rx_irq = irq_of_parse_and_map(np, 1);
-		lp->tx_irq = irq_of_parse_and_map(np, 0);
+	if (!np) {
+		dev_err(&pdev->dev, "could not find DMA node\n");
+		ret = -ENODEV;
+		goto free_netdev;
+	}
+	ret = of_address_to_resource(np, 0, &dmares);
+	if (ret) {
+		dev_err(&pdev->dev, "unable to get DMA resource\n");
 		of_node_put(np);
 		lp->eth_irq = platform_get_irq_optional(pdev, 0);
 	} else {
@@ -1921,11 +1915,16 @@ static int axienet_probe(struct platform_device *pdev)
 		lp->tx_irq = platform_get_irq(pdev, 0);
 		lp->eth_irq = platform_get_irq_optional(pdev, 2);
 	}
+	lp->dma_regs = devm_ioremap_resource(&pdev->dev, &dmares);
 	if (IS_ERR(lp->dma_regs)) {
 		dev_err(&pdev->dev, "could not map DMA regs\n");
 		ret = PTR_ERR(lp->dma_regs);
 		goto free_netdev;
 	}
+	lp->rx_irq = irq_of_parse_and_map(np, 1);
+	lp->tx_irq = irq_of_parse_and_map(np, 0);
+	lp->eth_irq = irq_of_parse_and_map(np, 2);
+	of_node_put(np);
 	if ((lp->rx_irq <= 0) || (lp->tx_irq <= 0)) {
 		dev_err(&pdev->dev, "could not determine irqs\n");
 		ret = -ENOMEM;
--- drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -811,27 +811,30 @@ axienet_start_xmit(struct sk_buff *skb, struct net_device *ndev)
  * axienet_recv - Is called from Axi DMA Rx Isr to complete the received
  *		  BD processing.
  * @ndev:	Pointer to net_device structure.
+ * @budget:	NAPI budget
  *
- * This function is invoked from the Axi DMA Rx isr to process the Rx BDs. It
- * does minimal processing and invokes "netif_rx" to complete further
- * processing.
+ * This function is invoked from the Axi DMA Rx isr(poll) to process the Rx BDs
+ * It does minimal processing and invokes "netif_receive_skb" to complete
+ * further processing.
+ * Return: Number of BD's processed.
  */
-static void axienet_recv(struct net_device *ndev)
+static int axienet_recv(struct net_device *ndev, int budget)
 {
 	u32 length;
 	u32 csumstatus;
 	u32 size = 0;
 	u32 packets = 0;
 	dma_addr_t tail_p = 0;
+	dma_addr_t phys;
 	struct axienet_local *lp = netdev_priv(ndev);
 	struct sk_buff *skb, *new_skb;
 	struct axidma_bd *cur_p;
+	unsigned int numbdfree = 0;
 
 	cur_p = &lp->rx_bd_v[lp->rx_bd_ci];
 
-	while ((cur_p->status & XAXIDMA_BD_STS_COMPLETE_MASK)) {
-		dma_addr_t phys;
-
+	while ((numbdfree < budget) &&
+	       (cur_p->status & XAXIDMA_BD_STS_COMPLETE_MASK)) {
 		tail_p = lp->rx_bd_p + sizeof(*lp->rx_bd_v) * lp->rx_bd_ci;
 
 		phys = desc_get_phys_addr(lp, cur_p);
@@ -862,14 +865,16 @@ static void axienet_recv(struct net_device *ndev)
 			skb->ip_summed = CHECKSUM_COMPLETE;
 		}
 
-		netif_rx(skb);
+		netif_receive_skb(skb);
 
 		size += length;
 		packets++;
 
 		new_skb = netdev_alloc_skb_ip_align(ndev, lp->max_frm_size);
-		if (!new_skb)
-			return;
+		if (new_skb == NULL) {
+			dev_err(lp->dev, "No memory for new_skb\n\r");
+			break;
+		}
 
 		phys = dma_map_single(ndev->dev.parent, new_skb->data,
 				      lp->max_frm_size,
@@ -878,7 +883,7 @@ static void axienet_recv(struct net_device *ndev)
 			if (net_ratelimit())
 				netdev_err(ndev, "RX DMA mapping error\n");
 			dev_kfree_skb(new_skb);
-			return;
+			return -ENOMEM;
 		}
 		desc_set_phys_addr(lp, phys, cur_p);
 
--- drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -730,14 +730,18 @@ axienet_start_xmit(struct sk_buff *skb, struct net_device *ndev)
 	dma_addr_t tail_p, phys;
 	struct axienet_local *lp = netdev_priv(ndev);
 	struct axidma_bd *cur_p;
-	u32 orig_tail_ptr = lp->tx_bd_tail;
+	u32 orig_tail_ptr = lp->tx_bd_tail; /* FIXME */
+	unsigned long flags;
 
 	num_frag = skb_shinfo(skb)->nr_frags;
 	cur_p = &lp->tx_bd_v[lp->tx_bd_tail];
 
+	spin_lock_irqsave(&lp->tx_lock, flags);
 	if (axienet_check_tx_bd_space(lp, num_frag)) {
-		if (netif_queue_stopped(ndev))
+		if (netif_queue_stopped(ndev)) {
+			spin_unlock_irqrestore(&lp->tx_lock, flags);
 			return NETDEV_TX_BUSY;
+		}
 
 		netif_stop_queue(ndev);
 
@@ -745,8 +749,10 @@ axienet_start_xmit(struct sk_buff *skb, struct net_device *ndev)
 		smp_mb();
 
 		/* Space might have just been freed - check again */
-		if (axienet_check_tx_bd_space(lp, num_frag))
+		if (axienet_check_tx_bd_space(lp, num_frag)) {
+			spin_unlock_irqrestore(&lp->tx_lock, flags);
 			return NETDEV_TX_BUSY;
+		}
 
 		netif_wake_queue(ndev);
 	}
--- drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -868,7 +875,11 @@ static int axienet_recv(struct net_device *ndev, int budget)
 
 		skb = cur_p->skb;
 		cur_p->skb = NULL;
-		length = cur_p->app4 & 0x0000FFFF;
+
+		if (lp->eth_hasnobuf)
+			length = cur_p->status & XAXIDMA_BD_STS_ACTUAL_LEN_MASK;
+		else
+			length = cur_p->app4 & 0x0000FFFF;
 
 		skb_put(skb, length);
 		skb->protocol = eth_type_trans(skb, ndev);
@@ -876,7 +887,8 @@ static int axienet_recv(struct net_device *ndev, int budget)
 		skb->ip_summed = CHECKSUM_NONE;
 
 		/* if we're doing Rx csum offload, set it up */
-		if (lp->features & XAE_FEATURE_FULL_RX_CSUM) {
+		if (lp->features & XAE_FEATURE_FULL_RX_CSUM &&
+		    !lp->eth_hasnobuf) {
 			csumstatus = (cur_p->app2 &
 				      XAE_FULL_CSUM_STATUS_MASK) >> 3;
 			if ((csumstatus == XAE_IP_TCP_CSUM_VALIDATED) ||
@@ -885,7 +897,7 @@ static int axienet_recv(struct net_device *ndev, int budget)
 			}
 		} else if ((lp->features & XAE_FEATURE_PARTIAL_RX_CSUM) != 0 &&
 			   skb->protocol == htons(ETH_P_IP) &&
-			   skb->len > 64) {
+			   skb->len > 64 && !lp->eth_hasnobuf) {
 			skb->csum = be32_to_cpu(cur_p->app3 & 0xFFFF);
 			skb->ip_summed = CHECKSUM_COMPLETE;
 		}
--- drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -865,7 +871,8 @@ static int axienet_recv(struct net_device *ndev, int budget)
 		skb = cur_p->skb;
 		cur_p->skb = NULL;
 
-		if (lp->eth_hasnobuf)
+		if (lp->eth_hasnobuf ||
+		    (lp->axienet_config->mactype != XAXIENET_1G))
 			length = cur_p->status & XAXIDMA_BD_STS_ACTUAL_LEN_MASK;
 		else
 			length = cur_p->app4 & 0x0000FFFF;
@@ -877,6 +884,7 @@ static int axienet_recv(struct net_device *ndev, int budget)
 
 		/* if we're doing Rx csum offload, set it up */
 		if (lp->features & XAE_FEATURE_FULL_RX_CSUM &&
+		    (lp->axienet_config->mactype == XAXIENET_1G) &&
 		    !lp->eth_hasnobuf) {
 			csumstatus = (cur_p->app2 &
 				      XAE_FULL_CSUM_STATUS_MASK) >> 3;
@@ -886,7 +894,8 @@ static int axienet_recv(struct net_device *ndev, int budget)
 			}
 		} else if ((lp->features & XAE_FEATURE_PARTIAL_RX_CSUM) != 0 &&
 			   skb->protocol == htons(ETH_P_IP) &&
-			   skb->len > 64 && !lp->eth_hasnobuf) {
+			   skb->len > 64 && !lp->eth_hasnobuf &&
+			   (lp->axienet_config->mactype == XAXIENET_1G)) {
 			skb->csum = be32_to_cpu(cur_p->app3 & 0xFFFF);
 			skb->ip_summed = CHECKSUM_COMPLETE;
 		}
@@ -2157,18 +2188,18 @@ static int axienet_probe(struct platform_device *pdev)
 		if (ret)
 			dev_warn(&pdev->dev,
 				 "error registering MDIO bus: %d\n", ret);
-	}
 
-	lp->phylink_config.dev = &ndev->dev;
-	lp->phylink_config.type = PHYLINK_NETDEV;
+		lp->phylink_config.dev = &ndev->dev;
+		lp->phylink_config.type = PHYLINK_NETDEV;
 
-	lp->phylink = phylink_create(&lp->phylink_config, pdev->dev.fwnode,
-				     lp->phy_mode,
-				     &axienet_phylink_ops);
-	if (IS_ERR(lp->phylink)) {
-		ret = PTR_ERR(lp->phylink);
-		dev_err(&pdev->dev, "phylink_create error (%i)\n", ret);
-		goto free_netdev;
+		lp->phylink = phylink_create(&lp->phylink_config, pdev->dev.fwnode,
+					     lp->phy_mode,
+					     &axienet_phylink_ops);
+		if (IS_ERR(lp->phylink)) {
+			ret = PTR_ERR(lp->phylink);
+			dev_err(&pdev->dev, "phylink_create error (%i)\n", ret);
+			goto free_netdev;
+		}
 	}
 
 	netif_napi_add(ndev, &lp->napi, xaxienet_rx_poll, XAXIENET_NAPI_WEIGHT);
--- drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -793,6 +854,7 @@ axienet_start_xmit(struct sk_buff *skb, struct net_device *ndev)
 	struct axidma_bd *cur_p;
 	u32 orig_tail_ptr = lp->tx_bd_tail; /* FIXME */
 	unsigned long flags;
+	u32 pad = 0;
 
 	num_frag = skb_shinfo(skb)->nr_frags;
 	cur_p = &lp->tx_bd_v[lp->tx_bd_tail];
@@ -2164,8 +2287,8 @@ static int axienet_probe(struct platform_device *pdev)
 			lp->phy_mode = PHY_INTERFACE_MODE_1000BASEX;
 			break;
 		default:
-			ret = -EINVAL;
-			goto free_netdev;
+			/* Don't error out as phy-type is an optional property */
+			break;
 		}
 	} else {
 		ret = of_get_phy_mode(pdev->dev.of_node, &lp->phy_mode);
@@ -2207,7 +2332,7 @@ static int axienet_probe(struct platform_device *pdev)
 	}
 	lp->rx_irq = irq_of_parse_and_map(np, 1);
 	lp->tx_irq = irq_of_parse_and_map(np, 0);
-	lp->eth_irq = irq_of_parse_and_map(np, 2);
+
 	of_node_put(np);
 	if ((lp->rx_irq <= 0) || (lp->tx_irq <= 0)) {
 		dev_err(&pdev->dev, "could not determine irqs\n");
--- drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -845,7 +987,7 @@ static int axienet_free_tx_chain(struct net_device *ndev, u32 first_bd,
 		cur_p->app2 = 0;
 		cur_p->app4 = 0;
 		cur_p->status = 0;
-		cur_p->skb = NULL;
+		cur_p->tx_skb = 0;
 
 		if (sizep)
 			*sizep += status & XAXIDMA_BD_STS_ACTUAL_LEN_MASK;
@@ -1198,6 +1452,36 @@ static int axienet_recv(struct net_device *ndev, int budget)
 			length = cur_p->app4 & 0x0000FFFF;
 
 		skb_put(skb, length);
+#ifdef CONFIG_XILINX_AXI_EMAC_HWTSTAMP
+		if ((lp->tstamp_config.rx_filter == HWTSTAMP_FILTER_ALL ||
+			lp->eth_hasptp) && (lp->axienet_config->mactype != XAXIENET_10G_25G)) {
+			u32 sec, nsec;
+			u64 time64;
+			struct skb_shared_hwtstamps *shhwtstamps;
+
+			if (lp->axienet_config->mactype == XAXIENET_1G ||
+			    lp->axienet_config->mactype == XAXIENET_2_5G) {
+				/* The first 8 bytes will be the timestamp */
+				memcpy(&sec, &skb->data[0], 4);
+				memcpy(&nsec, &skb->data[4], 4);
+
+				sec = cpu_to_be32(sec);
+				nsec = cpu_to_be32(nsec);
+			} else {
+				/* The first 8 bytes will be the timestamp */
+				memcpy(&nsec, &skb->data[0], 4);
+				memcpy(&sec, &skb->data[4], 4);
+			}
+
+			/* Remove these 8 bytes from the buffer */
+			skb_pull(skb, 8);
+			time64 = sec * NS_PER_SEC + nsec;
+			shhwtstamps = skb_hwtstamps(skb);
+			shhwtstamps->hwtstamp = ns_to_ktime(time64);
+		} else if (lp->axienet_config->mactype == XAXIENET_10G_25G) {
+			axienet_rx_hwtstamp(lp, skb);
+		}
+#endif
 		skb->protocol = eth_type_trans(skb, ndev);
 		/*skb_checksum_none_assert(skb);*/
 		skb->ip_summed = CHECKSUM_NONE;
--- drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -837,28 +837,26 @@ static int axienet_free_tx_chain(struct net_device *ndev, u32 first_bd,
 	dma_addr_t phys;
 	int i;
 
-	if (max_bds == -1)
-		max_bds = lp->tx_bd_num;
-
-	for (i = 0; i < max_bds; i++) {
-		cur_p = &lp->tx_bd_v[(first_bd + i) % lp->tx_bd_num];
-		status = cur_p->status;
-
-		/* If no number is given, clean up *all* descriptors that have
-		 * been completed by the MAC.
-		 */
-		if (nr_bds == -1 && !(status & XAXIDMA_BD_STS_COMPLETE_MASK))
-			break;
-
-		phys = desc_get_phys_addr(lp, cur_p);
-		dma_unmap_single(ndev->dev.parent, phys,
-				 (cur_p->cntrl & XAXIDMA_BD_CTRL_LENGTH_MASK),
-				 DMA_TO_DEVICE);
-
-		if (cur_p->skb && (status & XAXIDMA_BD_STS_COMPLETE_MASK))
-			dev_consume_skb_irq(cur_p->skb);
-
-		cur_p->cntrl = 0;
+	cur_p = &lp->tx_bd_v[lp->tx_bd_ci];
+	status = cur_p->status;
+	while (status & XAXIDMA_BD_STS_COMPLETE_MASK) {
+#ifdef CONFIG_XILINX_AXI_EMAC_HWTSTAMP
+		if (cur_p->ptp_tx_skb)
+			axienet_tx_hwtstamp(lp, cur_p);
+#endif
+		if (cur_p->tx_desc_mapping == DESC_DMA_MAP_PAGE)
+			dma_unmap_page(ndev->dev.parent, cur_p->phys,
+				       cur_p->cntrl &
+				       XAXIDMA_BD_CTRL_LENGTH_MASK,
+				       DMA_TO_DEVICE);
+		else
+			dma_unmap_single(ndev->dev.parent, cur_p->phys,
+					 cur_p->cntrl &
+					 XAXIDMA_BD_CTRL_LENGTH_MASK,
+					 DMA_TO_DEVICE);
+		if (cur_p->tx_skb)
+			dev_kfree_skb_irq((struct sk_buff *)cur_p->tx_skb);
+		/*cur_p->phys = 0;*/
 		cur_p->app0 = 0;
 		cur_p->app1 = 0;
 		cur_p->app2 = 0;
--- drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -1267,7 +1267,7 @@ static int axienet_recv(struct net_device *ndev, int budget)
 		size += length;
 		packets++;
 
-		new_skb = netdev_alloc_skb_ip_align(ndev, lp->max_frm_size);
+		new_skb = netdev_alloc_skb(ndev, lp->max_frm_size);
 		if (new_skb == NULL) {
 			dev_err(lp->dev, "No memory for new_skb\n\r");
 			break;
--- drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -921,6 +921,7 @@ static inline int axienet_check_tx_bd_space(struct axienet_local *lp,
 					    int num_frag)
 {
 	struct axidma_bd *cur_p;
+
 	cur_p = &lp->tx_bd_v[(lp->tx_bd_tail + num_frag) % lp->tx_bd_num];
 	if (cur_p->status & XAXIDMA_BD_STS_ALL_MASK)
 		return NETDEV_TX_BUSY;
@@ -1268,7 +1269,7 @@ static int axienet_recv(struct net_device *ndev, int budget)
 		packets++;
 
 		new_skb = netdev_alloc_skb(ndev, lp->max_frm_size);
-		if (new_skb == NULL) {
+		if (!new_skb) {
 			dev_err(lp->dev, "No memory for new_skb\n\r");
 			break;
 		}
@@ -2811,6 +2816,7 @@ static int axienet_probe(struct platform_device *pdev)
 	ret = register_netdev(lp->ndev);
 	if (ret) {
 		dev_err(lp->dev, "register_netdev() error (%i)\n", ret);
+		axienet_mdio_teardown(lp);
 		goto free_netdev;
 	}
 
--- drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -3115,11 +3386,13 @@ static int axienet_probe(struct platform_device *pdev)
 	if (ret) {
 		dev_err(lp->dev, "register_netdev() error (%i)\n", ret);
 		axienet_mdio_teardown(lp);
-		goto free_netdev;
+		goto err_disable_clk;
 	}
 
 	return 0;
 
+err_disable_clk:
+	axienet_clk_disable(pdev);
 free_netdev:
 	free_netdev(ndev);
 
--- drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -388,19 +186,18 @@ static int __axienet_device_reset(struct axienet_local *lp)
 	 * Note that even though both TX and RX have their own reset register,
 	 * they both reset the entire DMA core, so only one needs to be used.
 	 */
-	axienet_dma_out32(lp, XAXIDMA_TX_CR_OFFSET, XAXIDMA_CR_RESET_MASK);
+	axienet_dma_out32(q, XAXIDMA_TX_CR_OFFSET, XAXIDMA_CR_RESET_MASK);
 	timeout = DELAY_OF_ONE_MILLISEC;
-	while (axienet_dma_in32(lp, XAXIDMA_TX_CR_OFFSET) &
+	while (axienet_dma_in32(q, XAXIDMA_TX_CR_OFFSET) &
 				XAXIDMA_CR_RESET_MASK) {
 		udelay(1);
 		if (--timeout == 0) {
-			netdev_err(lp->ndev, "%s: DMA reset timeout!\n",
+			netdev_err(q->lp->ndev, "%s: DMA reset timeout!\n",
 				   __func__);
-			return -ETIMEDOUT;
+			break;
 		}
 	}
 
-	return 0;
 }
 
 /**
@@ -641,29 +449,38 @@ static void axienet_rx_hwtstamp(struct axienet_local *lp,
 #endif
 
 /**
- * axienet_free_tx_chain - Clean up a series of linked TX descriptors.
+ * axienet_start_xmit_done - Invoked once a transmit is completed by the
+ * Axi DMA Tx channel.
  * @ndev:	Pointer to the net_device structure
- * @first_bd:	Index of first descriptor to clean up
- * @nr_bds:	Number of descriptors to clean up, can be -1 if unknown.
- * @sizep:	Pointer to a u32 filled with the total sum of all bytes
- * 		in all cleaned-up descriptors. Ignored if NULL.
+ * @q:		Pointer to DMA queue structure
  *
- * Would either be called after a successful transmit operation, or after
- * there was an error when setting up the chain.
- * Returns the number of descriptors handled.
+ * This function is invoked from the Axi DMA Tx isr to notify the completion
+ * of transmit operation. It clears fields in the corresponding Tx BDs and
+ * unmaps the corresponding buffer so that CPU can regain ownership of the
+ * buffer. It finally invokes "netif_wake_queue" to restart transmission if
+ * required.
  */
-static int axienet_free_tx_chain(struct net_device *ndev, u32 first_bd,
-				 int nr_bds, u32 *sizep)
+void axienet_start_xmit_done(struct net_device *ndev,
+			     struct axienet_dma_q *q)
 {
+	u32 size = 0;
+	u32 packets = 0;
 	struct axienet_local *lp = netdev_priv(ndev);
+
+#ifdef CONFIG_AXIENET_HAS_MCDMA
+	struct aximcdma_bd *cur_p;
+#else
 	struct axidma_bd *cur_p;
-	int max_bds = nr_bds;
+#endif
 	unsigned int status = 0;
-	dma_addr_t phys;
-	int i;
 
-	cur_p = &lp->tx_bd_v[lp->tx_bd_ci];
+#ifdef CONFIG_AXIENET_HAS_MCDMA
+	cur_p = &q->txq_bd_v[q->tx_bd_ci];
+	status = cur_p->sband_stats;
+#else
+	cur_p = &q->tx_bd_v[q->tx_bd_ci];
 	status = cur_p->status;
+#endif
 	while (status & XAXIDMA_BD_STS_COMPLETE_MASK) {
 #ifdef CONFIG_XILINX_AXI_EMAC_HWTSTAMP
 		if (cur_p->ptp_tx_skb)
@@ -688,49 +505,43 @@ static int axienet_free_tx_chain(struct net_device *ndev, u32 first_bd,
 		cur_p->app4 = 0;
 		cur_p->status = 0;
 		cur_p->tx_skb = 0;
+#ifdef CONFIG_AXIENET_HAS_MCDMA
+		cur_p->sband_stats = 0;
+#endif
 
-		if (sizep)
-			*sizep += status & XAXIDMA_BD_STS_ACTUAL_LEN_MASK;
-	}
-
-	return i;
-}
-
-/**
- * axienet_start_xmit_done - Invoked once a transmit is completed by the
- * Axi DMA Tx channel.
- * @ndev:	Pointer to the net_device structure
- *
- * This function is invoked from the Axi DMA Tx isr to notify the completion
- * of transmit operation. It clears fields in the corresponding Tx BDs and
- * unmaps the corresponding buffer so that CPU can regain ownership of the
- * buffer. It finally invokes "netif_wake_queue" to restart transmission if
- * required.
- */
-static void axienet_start_xmit_done(struct net_device *ndev)
-{
-	struct axienet_local *lp = netdev_priv(ndev);
-	u32 packets = 0;
-	u32 size = 0;
-
-	packets = axienet_free_tx_chain(ndev, lp->tx_bd_ci, -1, &size);
+		size += status & XAXIDMA_BD_STS_ACTUAL_LEN_MASK;
+		packets++;
 
-	lp->tx_bd_ci += packets;
-	if (lp->tx_bd_ci >= lp->tx_bd_num)
-		lp->tx_bd_ci -= lp->tx_bd_num;
+		if (++q->tx_bd_ci >= lp->tx_bd_num)
+			q->tx_bd_ci = 0;
+#ifdef CONFIG_AXIENET_HAS_MCDMA
+		cur_p = &q->txq_bd_v[q->tx_bd_ci];
+		status = cur_p->sband_stats;
+#else
+		cur_p = &q->tx_bd_v[q->tx_bd_ci];
+		status = cur_p->status;
+#endif
+	}
 
 	ndev->stats.tx_packets += packets;
 	ndev->stats.tx_bytes += size;
+	q->tx_packets += packets;
+	q->tx_bytes += size;
 
 	/* Matches barrier in axienet_start_xmit */
 	smp_mb();
 
-	netif_wake_queue(ndev);
+	/* Fixme: With the existing multiqueue implementation
+	 * in the driver it is difficult to get the exact queue info.
+	 * We should wake only the particular queue
+	 * instead of waking all ndev queues.
+	 */
+	netif_tx_wake_all_queues(ndev);
 }
 
 /**
  * axienet_check_tx_bd_space - Checks if a BD/group of BDs are currently busy
- * @lp:		Pointer to the axienet_local structure
+ * @q:		Pointer to DMA queue structure
  * @num_frag:	The number of BDs to check for
  *
  * Return: 0, on success
@@ -741,34 +552,52 @@ static void axienet_start_xmit_done(struct net_device *ndev)
  * transmission. If the BD or any of the BDs are not free the function
  * returns a busy status. This is invoked from axienet_start_xmit.
  */
-static inline int axienet_check_tx_bd_space(struct axienet_local *lp,
+static inline int axienet_check_tx_bd_space(struct axienet_dma_q *q,
 					    int num_frag)
 {
+	struct axienet_local *lp = q->lp;
+#ifdef CONFIG_AXIENET_HAS_MCDMA
+	struct aximcdma_bd *cur_p;
+
+	cur_p = &q->txq_bd_v[(q->tx_bd_tail + num_frag) % lp->tx_bd_num];
+	if (cur_p->sband_stats & XMCDMA_BD_STS_ALL_MASK)
+		return NETDEV_TX_BUSY;
+#else
 	struct axidma_bd *cur_p;
 
-	cur_p = &lp->tx_bd_v[(lp->tx_bd_tail + num_frag) % lp->tx_bd_num];
+	cur_p = &q->tx_bd_v[(q->tx_bd_tail + num_frag) % lp->tx_bd_num];
 	if (cur_p->status & XAXIDMA_BD_STS_ALL_MASK)
 		return NETDEV_TX_BUSY;
+#endif
 	return 0;
 }
 
 #ifdef CONFIG_XILINX_AXI_EMAC_HWTSTAMP
 /**
  * axienet_create_tsheader - Create timestamp header for tx
- * @lp:		Pointer to axienet local structure
+ * @q:		Pointer to DMA queue structure
  * @buf:	Pointer to the buf to copy timestamp header
  * @msg_type:	PTP message type
  *
  * Return:	None.
  */
-static void axienet_create_tsheader(struct axienet_local *lp, u8 *buf,
-				    u8 msg_type)
+static void axienet_create_tsheader(u8 *buf, u8 msg_type,
+				    struct axienet_dma_q *q)
 {
+	struct axienet_local *lp = q->lp;
+#ifdef CONFIG_AXIENET_HAS_MCDMA
+	struct aximcdma_bd *cur_p;
+#else
 	struct axidma_bd *cur_p;
+#endif
 	u64 val;
 	u32 tmp;
 
-	cur_p = &lp->tx_bd_v[lp->tx_bd_tail];
+#ifdef CONFIG_AXIENET_HAS_MCDMA
+	cur_p = &q->txq_bd_v[q->tx_bd_tail];
+#else
+	cur_p = &q->tx_bd_v[q->tx_bd_tail];
+#endif
 
 	if (msg_type == TX_TS_OP_NOOP) {
 		buf[0] = TX_TS_OP_NOOP;
@@ -796,83 +625,49 @@ static void axienet_create_tsheader(struct axienet_local *lp, u8 *buf,
 }
 #endif
 
-/**
- * axienet_start_xmit - Starts the transmission.
- * @skb:	sk_buff pointer that contains data to be Txed.
- * @ndev:	Pointer to net_device structure.
- *
- * Return: NETDEV_TX_OK, on success
- *	    NETDEV_TX_BUSY, if any of the descriptors are not free
- *
- * This function is invoked from upper layers to initiate transmission. The
- * function uses the next available free BDs and populates their fields to
- * start the transmission. Additionally if checksum offloading is supported,
- * it populates AXI Stream Control fields with appropriate values.
- */
-static netdev_tx_t
-axienet_start_xmit(struct sk_buff *skb, struct net_device *ndev)
+#ifdef CONFIG_XILINX_AXI_EMAC_HWTSTAMP
+static int axienet_skb_tstsmp(struct sk_buff **__skb, struct axienet_dma_q *q,
+			      struct net_device *ndev)
 {
-	u32 ii;
-	u32 num_frag;
-	u32 csum_start_off;
-	u32 csum_index_off;
-	skb_frag_t *frag;
-	dma_addr_t tail_p, phys;
-	struct axienet_local *lp = netdev_priv(ndev);
+#ifdef CONFIG_AXIENET_HAS_MCDMA
+	struct aximcdma_bd *cur_p;
+#else
 	struct axidma_bd *cur_p;
-	u32 orig_tail_ptr = lp->tx_bd_tail; /* FIXME */
-	unsigned long flags;
-	u32 pad = 0;
-
-	num_frag = skb_shinfo(skb)->nr_frags;
-	cur_p = &lp->tx_bd_v[lp->tx_bd_tail];
-
-	spin_lock_irqsave(&lp->tx_lock, flags);
-	if (axienet_check_tx_bd_space(lp, num_frag)) {
-		if (netif_queue_stopped(ndev)) {
-			spin_unlock_irqrestore(&lp->tx_lock, flags);
-			return NETDEV_TX_BUSY;
-		}
-
-		netif_stop_queue(ndev);
-
-		/* Matches barrier in axienet_start_xmit_done */
-		smp_mb();
-
-		/* Space might have just been freed - check again */
-		if (axienet_check_tx_bd_space(lp, num_frag)) {
-			spin_unlock_irqrestore(&lp->tx_lock, flags);
-			return NETDEV_TX_BUSY;
-		}
-
-		netif_wake_queue(ndev);
-	}
+#endif
+	struct axienet_local *lp = netdev_priv(ndev);
+	struct sk_buff *old_skb = *__skb;
+	struct sk_buff *skb = *__skb;
 
-#ifdef CONFIG_XILINX_AXI_EMAC_HWTSTAMP
+#ifdef CONFIG_AXIENET_HAS_MCDMA
+	cur_p = &q->txq_bd_v[q->tx_bd_tail];
+#else
+	cur_p = &q->tx_bd_v[q->tx_bd_tail];
+#endif
 
 	if ((((lp->tstamp_config.tx_type == HWTSTAMP_TX_ONESTEP_SYNC) ||
-	     (lp->tstamp_config.tx_type == HWTSTAMP_TX_ON)) ||
-	     lp->eth_hasptp) && (lp->axienet_config->mactype != XAXIENET_10G_25G)) {
+	      (lp->tstamp_config.tx_type == HWTSTAMP_TX_ON)) ||
+	       lp->eth_hasptp) && (lp->axienet_config->mactype !=
+	       XAXIENET_10G_25G)) {
 		u8 *tmp;
 		struct sk_buff *new_skb;
 
-		if (skb_headroom(skb) < AXIENET_TS_HEADER_LEN) {
-			new_skb = skb_realloc_headroom(skb,
-						       AXIENET_TS_HEADER_LEN);
+		if (skb_headroom(old_skb) < AXIENET_TS_HEADER_LEN) {
+			new_skb =
+			skb_realloc_headroom(old_skb,
+					     AXIENET_TS_HEADER_LEN);
 			if (!new_skb) {
-				dev_err(&ndev->dev, "failed "
-					"to allocate new socket buffer\n");
-				dev_kfree_skb_any(skb);
-				spin_unlock_irqrestore(&lp->tx_lock, flags);
-				return NETDEV_TX_OK;
+				dev_err(&ndev->dev, "failed to allocate new socket buffer\n");
+				dev_kfree_skb_any(old_skb);
+				return NETDEV_TX_BUSY;
 			}
 
 			/*  Transfer the ownership to the
 			 *  new socket buffer if required
 			 */
-			if (skb->sk)
-				skb_set_owner_w(new_skb, skb->sk);
-			dev_kfree_skb(skb);
+			if (old_skb->sk)
+				skb_set_owner_w(new_skb, old_skb->sk);
+			dev_kfree_skb_any(old_skb);
+			*__skb = new_skb;
 			skb = new_skb;
 		}
 
@@ -1035,74 +890,122 @@ axienet_start_xmit(struct sk_buff *skb, struct net_device *ndev)
 		u32 len;
 		skb_frag_t *frag;
 
-		if (++lp->tx_bd_tail >= lp->tx_bd_num)
-			lp->tx_bd_tail = 0;
+		if (++q->tx_bd_tail >= lp->tx_bd_num)
+			q->tx_bd_tail = 0;
 
-		cur_p = &lp->tx_bd_v[lp->tx_bd_tail];
+#ifdef CONFIG_AXIENET_HAS_MCDMA
+		cur_p = &q->txq_bd_v[q->tx_bd_tail];
+#else
+		cur_p = &q->tx_bd_v[q->tx_bd_tail];
+#endif
 		frag = &skb_shinfo(skb)->frags[ii];
 		len = skb_frag_size(frag);
 		cur_p->phys = skb_frag_dma_map(ndev->dev.parent, frag, 0, len,
 					       DMA_TO_DEVICE);
-		cur_p->cntrl = len + pad;
+		cur_p->cntrl = len;
 		cur_p->tx_desc_mapping = DESC_DMA_MAP_PAGE;
 	}
 
 out:
+#ifdef CONFIG_AXIENET_HAS_MCDMA
+	cur_p->cntrl |= XMCDMA_BD_CTRL_TXEOF_MASK;
+	tail_p = q->tx_bd_p + sizeof(*q->txq_bd_v) * q->tx_bd_tail;
+#else
 	cur_p->cntrl |= XAXIDMA_BD_CTRL_TXEOF_MASK;
+	tail_p = q->tx_bd_p + sizeof(*q->tx_bd_v) * q->tx_bd_tail;
+#endif
+	cur_p->tx_skb = (phys_addr_t)skb;
 	cur_p->tx_skb = (phys_addr_t)skb;
 
-	tail_p = lp->tx_bd_p + sizeof(*lp->tx_bd_v) * lp->tx_bd_tail;
+	tail_p = q->tx_bd_p + sizeof(*q->tx_bd_v) * q->tx_bd_tail;
 	/* Ensure BD write before starting transfer */
 	wmb();
 
 	/* Start the transfer */
-	axienet_dma_bdout(lp, XAXIDMA_TX_TDESC_OFFSET, tail_p);
-	if (++lp->tx_bd_tail >= lp->tx_bd_num)
-		lp->tx_bd_tail = 0;
+#ifdef CONFIG_AXIENET_HAS_MCDMA
+	axienet_dma_bdout(q, XMCDMA_CHAN_TAILDESC_OFFSET(q->chan_id),
+			  tail_p);
+#else
+	axienet_dma_bdout(q, XAXIDMA_TX_TDESC_OFFSET, tail_p);
+#endif
+	if (++q->tx_bd_tail >= lp->tx_bd_num)
+		q->tx_bd_tail = 0;
 
-	spin_unlock_irqrestore(&lp->tx_lock, flags);
+	spin_unlock_irqrestore(&q->tx_lock, flags);
 
 	return NETDEV_TX_OK;
 }
 
+/**
+ * axienet_start_xmit - Starts the transmission.
+ * @skb:	sk_buff pointer that contains data to be Txed.
+ * @ndev:	Pointer to net_device structure.
+ *
+ * Return: NETDEV_TX_OK, on success
+ *	    NETDEV_TX_BUSY, if any of the descriptors are not free
+ *
+ * This function is invoked from upper layers to initiate transmission. The
+ * function uses the next available free BDs and populates their fields to
+ * start the transmission. Additionally if checksum offloading is supported,
+ * it populates AXI Stream Control fields with appropriate values.
+ */
+static int axienet_start_xmit(struct sk_buff *skb, struct net_device *ndev)
+{
+	u16 map = skb_get_queue_mapping(skb); /* Single dma queue default*/
+
+	return axienet_queue_xmit(skb, ndev, map);
+}
+
 /**
  * axienet_recv - Is called from Axi DMA Rx Isr to complete the received
  *		  BD processing.
  * @ndev:	Pointer to net_device structure.
  * @budget:	NAPI budget
+ * @q:		Pointer to axienet DMA queue structure
  *
  * This function is invoked from the Axi DMA Rx isr(poll) to process the Rx BDs
  * It does minimal processing and invokes "netif_receive_skb" to complete
  * further processing.
  * Return: Number of BD's processed.
  */
-static int axienet_recv(struct net_device *ndev, int budget)
+static int axienet_recv(struct net_device *ndev, int budget,
+			struct axienet_dma_q *q)
 {
 	u32 length;
 	u32 csumstatus;
 	u32 size = 0;
 	u32 packets = 0;
 	dma_addr_t tail_p = 0;
-	dma_addr_t phys;
 	struct axienet_local *lp = netdev_priv(ndev);
 	struct sk_buff *skb, *new_skb;
+#ifdef CONFIG_AXIENET_HAS_MCDMA
+	struct aximcdma_bd *cur_p;
+#else
 	struct axidma_bd *cur_p;
+#endif
 	unsigned int numbdfree = 0;
 
 	/* Get relevat BD status value */
 	rmb();
-	cur_p = &lp->rx_bd_v[lp->rx_bd_ci];
+#ifdef CONFIG_AXIENET_HAS_MCDMA
+	cur_p = &q->rxq_bd_v[q->rx_bd_ci];
+#else
+	cur_p = &q->rx_bd_v[q->rx_bd_ci];
+#endif
 
 	while ((numbdfree < budget) &&
 	       (cur_p->status & XAXIDMA_BD_STS_COMPLETE_MASK)) {
-		tail_p = lp->rx_bd_p + sizeof(*lp->rx_bd_v) * lp->rx_bd_ci;
+#ifdef CONFIG_AXIENET_HAS_MCDMA
+		tail_p = q->rx_bd_p + sizeof(*q->rxq_bd_v) * q->rx_bd_ci;
+#else
+		tail_p = q->rx_bd_p + sizeof(*q->rx_bd_v) * q->rx_bd_ci;
+#endif
 
-		phys = desc_get_phys_addr(lp, cur_p);
-		dma_unmap_single(ndev->dev.parent, phys, lp->max_frm_size,
+		dma_unmap_single(ndev->dev.parent, cur_p->phys,
+				 lp->max_frm_size,
 				 DMA_FROM_DEVICE);
 
-		skb = cur_p->skb;
-		cur_p->skb = NULL;
+		skb = (struct sk_buff *)(cur_p->sw_id_offset);
 
 		if (lp->eth_hasnobuf ||
 		    (lp->axienet_config->mactype != XAXIENET_1G))
@@ -1179,35 +1082,39 @@ static int axienet_recv(struct net_device *ndev, int budget)
 		 */
 		wmb();
 
-		phys = dma_map_single(ndev->dev.parent, new_skb->data,
-				      lp->max_frm_size,
-				      DMA_FROM_DEVICE);
-		if (unlikely(dma_mapping_error(ndev->dev.parent, phys))) {
-			if (net_ratelimit())
-				netdev_err(ndev, "RX DMA mapping error\n");
-			dev_kfree_skb(new_skb);
-			return -ENOMEM;
-		}
-		desc_set_phys_addr(lp, phys, cur_p);
-
+		cur_p->phys = dma_map_single(ndev->dev.parent, new_skb->data,
+					   lp->max_frm_size,
+					   DMA_FROM_DEVICE);
 		cur_p->cntrl = lp->max_frm_size;
 		cur_p->status = 0;
-		cur_p->skb = new_skb;
+		cur_p->sw_id_offset = (phys_addr_t)new_skb;
 
-		if (++lp->rx_bd_ci >= lp->rx_bd_num)
-			lp->rx_bd_ci = 0;
+		if (++q->rx_bd_ci >= lp->rx_bd_num)
+			q->rx_bd_ci = 0;
 
 		/* Get relevat BD status value */
 		rmb();
-		cur_p = &lp->rx_bd_v[lp->rx_bd_ci];
+#ifdef CONFIG_AXIENET_HAS_MCDMA
+		cur_p = &q->rxq_bd_v[q->rx_bd_ci];
+#else
+		cur_p = &q->rx_bd_v[q->rx_bd_ci];
+#endif
 		numbdfree++;
 	}
 
 	ndev->stats.rx_packets += packets;
 	ndev->stats.rx_bytes += size;
+	q->rx_packets += packets;
+	q->rx_bytes += size;
 
-	if (tail_p)
-		axienet_dma_bdout(lp, XAXIDMA_RX_TDESC_OFFSET, tail_p);
+	if (tail_p) {
+#ifdef CONFIG_AXIENET_HAS_MCDMA
+		axienet_dma_bdout(q, XMCDMA_CHAN_TAILDESC_OFFSET(q->chan_id) +
+				  q->rx_offset, tail_p);
+#else
+		axienet_dma_bdout(q, XAXIDMA_RX_TDESC_OFFSET, tail_p);
+#endif
+	}
 
 	return numbdfree;
 }
@@ -2720,8 +2670,11 @@ static int axienet_probe(struct platform_device *pdev)
 	lp->ndev = ndev;
 	lp->dev = &pdev->dev;
 	lp->options = XAE_OPTION_DEFAULTS;
+	lp->num_tx_queues = num_queues;
+	lp->num_rx_queues = num_queues;
 	lp->rx_bd_num = RX_BD_NUM_DEFAULT;
 	lp->tx_bd_num = TX_BD_NUM_DEFAULT;
+
 	/* Map device registers */
 	ethres = platform_get_resource(pdev, IORESOURCE_MEM, 0);
 	lp->regs = devm_ioremap_resource(&pdev->dev, ethres);
@@ -2885,86 +2838,31 @@ static int axienet_probe(struct platform_device *pdev)
 
 	of_node_put(np);
 #endif
+	if (!slave) {
+#ifdef CONFIG_AXIENET_HAS_MCDMA
+		ret = axienet_mcdma_probe(pdev, lp, ndev);
+#else
+		ret = axienet_dma_probe(pdev, ndev);
+#endif
+		if (ret) {
+			pr_err("Getting DMA resource failed\n");
+			goto free_netdev;
+		}
 
-	/* Find the DMA node, map the DMA registers, and decode the DMA IRQs */
-	np = of_parse_phandle(pdev->dev.of_node, "axistream-connected", 0);
-	if (!np) {
-		dev_err(&pdev->dev, "could not find DMA node\n");
-		ret = -ENODEV;
-		goto free_netdev;
-	}
-	ret = of_address_to_resource(np, 0, &dmares);
-	if (ret) {
-		dev_err(&pdev->dev, "unable to get DMA resource\n");
-		of_node_put(np);
-		lp->eth_irq = platform_get_irq_optional(pdev, 0);
-	} else {
-		/* Check for these resources directly on the Ethernet node. */
-		struct resource *res = platform_get_resource(pdev,
-							     IORESOURCE_MEM, 1);
-		lp->dma_regs = devm_ioremap_resource(&pdev->dev, res);
-		lp->rx_irq = platform_get_irq(pdev, 1);
-		lp->tx_irq = platform_get_irq(pdev, 0);
-		lp->eth_irq = platform_get_irq_optional(pdev, 2);
-	}
-	lp->dma_regs = devm_ioremap_resource(&pdev->dev, &dmares);
-	if (IS_ERR(lp->dma_regs)) {
-		ret = PTR_ERR(lp->dma_regs);
-		goto free_netdev;
-	}
-	lp->rx_irq = irq_of_parse_and_map(np, 1);
-	lp->tx_irq = irq_of_parse_and_map(np, 0);
-
-	of_node_put(np);
-	if ((lp->rx_irq <= 0) || (lp->tx_irq <= 0)) {
-		dev_err(&pdev->dev, "could not determine irqs\n");
-		ret = -ENOMEM;
-		goto free_netdev;
-	}
-	lp->eth_hasdre = of_property_read_bool(np, "xlnx,include-dre");
-
-	/* Autodetect the need for 64-bit DMA pointers.
-	 * When the IP is configured for a bus width bigger than 32 bits,
-	 * writing the MSB registers is mandatory, even if they are all 0.
-	 * We can detect this case by writing all 1's to one such register
-	 * and see if that sticks: when the IP is configured for 32 bits
-	 * only, those registers are RES0.
-	 * Those MSB registers were introduced in IP v7.1, which we check first.
-	 */
-	if ((axienet_ior(lp, XAE_ID_OFFSET) >> 24) >= 0x9) {
-		void __iomem *desc = lp->dma_regs + XAXIDMA_TX_CDESC_OFFSET + 4;
-
-		iowrite32(0x0, desc);
-		if (ioread32(desc) == 0) {	/* sanity check */
-			iowrite32(0xffffffff, desc);
-			if (ioread32(desc) > 0) {
-				lp->features |= XAE_FEATURE_DMA_64BIT;
-				addr_width = 64;
-				dev_info(&pdev->dev,
-					 "autodetected 64-bit DMA range\n");
+		if (dma_set_mask_and_coherent(lp->dev, DMA_BIT_MASK(lp->dma_mask)) != 0) {
+			dev_warn(&pdev->dev, "default to %d-bit dma mask\n", XAE_DMA_MASK_MIN);
+			if (dma_set_mask_and_coherent(lp->dev, DMA_BIT_MASK(XAE_DMA_MASK_MIN)) != 0) {
+				dev_err(&pdev->dev, "dma_set_mask_and_coherent failed, aborting\n");
+				goto free_netdev;
 			}
-			iowrite32(0x0, desc);
 		}
-	}
-
-	ret = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(addr_width));
-	if (ret) {
-		dev_err(&pdev->dev, "No suitable DMA available\n");
-		goto free_netdev;
-	}
-
-	/* Check for Ethernet core IRQ (optional) */
-	if (lp->eth_irq <= 0)
-		dev_info(&pdev->dev, "Ethernet core IRQ not defined\n");
 
-	spin_lock_init(&lp->tx_lock);
-	spin_lock_init(&lp->rx_lock);
-
-	ret = axienet_dma_clk_init(pdev);
-	if (ret) {
-		if (ret != -EPROBE_DEFER)
-			dev_err(&pdev->dev, "DMA clock init failed %d\n", ret);
-		goto free_netdev;
+		ret = axienet_dma_clk_init(pdev);
+		if (ret) {
+			if (ret != -EPROBE_DEFER)
+				dev_err(&pdev->dev, "DMA clock init failed %d\n", ret);
+			goto free_netdev;
+		}
 	}
 
 	ret = axienet_clk_init(pdev, &lp->aclk, &lp->eth_sclk,
--- drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -760,12 +761,18 @@ static inline int axienet_check_tx_bd_space(struct axienet_dma_q *q,
 #ifdef CONFIG_AXIENET_HAS_MCDMA
 	struct aximcdma_bd *cur_p;
 
+	if (CIRC_SPACE(q->tx_bd_tail, q->tx_bd_ci, lp->tx_bd_num) < (num_frag + 1))
+		return NETDEV_TX_BUSY;
+
 	cur_p = &q->txq_bd_v[(q->tx_bd_tail + num_frag) % lp->tx_bd_num];
 	if (cur_p->sband_stats & XMCDMA_BD_STS_ALL_MASK)
 		return NETDEV_TX_BUSY;
 #else
 	struct axidma_bd *cur_p;
 
+	if (CIRC_SPACE(q->tx_bd_tail, q->tx_bd_ci, lp->tx_bd_num) < (num_frag + 1))
+		return NETDEV_TX_BUSY;
+
 	cur_p = &q->tx_bd_v[(q->tx_bd_tail + num_frag) % lp->tx_bd_num];
 	if (cur_p->status & XAXIDMA_BD_STS_ALL_MASK)
 		return NETDEV_TX_BUSY;
--- drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -1142,6 +1142,11 @@ static int axienet_recv(struct net_device *ndev, int budget,
 
 	while ((numbdfree < budget) &&
 	       (cur_p->status & XAXIDMA_BD_STS_COMPLETE_MASK)) {
+		new_skb = netdev_alloc_skb(ndev, lp->max_frm_size);
+		if (!new_skb) {
+			dev_err(lp->dev, "No memory for new_skb\n");
+			break;
+		}
 #ifdef CONFIG_AXIENET_HAS_MCDMA
 		tail_p = q->rx_bd_p + sizeof(*q->rxq_bd_v) * q->rx_bd_ci;
 #else
@@ -1218,12 +1223,6 @@ static int axienet_recv(struct net_device *ndev, int budget,
 		size += length;
 		packets++;
 
-		new_skb = netdev_alloc_skb(ndev, lp->max_frm_size);
-		if (!new_skb) {
-			dev_err(lp->dev, "No memory for new_skb\n\r");
-			break;
-		}
-
 		/* Ensure that the skb is completely updated
 		 * prio to mapping the DMA
 		 */
--- drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -2436,141 +2503,6 @@ static int __maybe_unused axienet_dma_probe(struct platform_device *pdev,
 	return 0;
 }
 
-static void axienet_validate(struct phylink_config *config,
-			     unsigned long *supported,
-			     struct phylink_link_state *state)
-{
-	struct net_device *ndev = to_net_dev(config->dev);
-	struct axienet_local *lp = netdev_priv(ndev);
-	__ETHTOOL_DECLARE_LINK_MODE_MASK(mask) = { 0, };
-
-	/* Only support the mode we are configured for */
-	if (state->interface != PHY_INTERFACE_MODE_NA &&
-	    state->interface != lp->phy_mode) {
-		netdev_warn(ndev, "Cannot use PHY mode %s, supported: %s\n",
-			    phy_modes(state->interface),
-			    phy_modes(lp->phy_mode));
-		bitmap_zero(supported, __ETHTOOL_LINK_MODE_MASK_NBITS);
-		return;
-	}
-
-	phylink_set(mask, Autoneg);
-	phylink_set_port_modes(mask);
-
-	phylink_set(mask, Asym_Pause);
-	phylink_set(mask, Pause);
-	phylink_set(mask, 1000baseX_Full);
-	phylink_set(mask, 10baseT_Full);
-	phylink_set(mask, 100baseT_Full);
-	phylink_set(mask, 1000baseT_Full);
-
-	bitmap_and(supported, supported, mask,
-		   __ETHTOOL_LINK_MODE_MASK_NBITS);
-	bitmap_and(state->advertising, state->advertising, mask,
-		   __ETHTOOL_LINK_MODE_MASK_NBITS);
-}
-
-static void axienet_mac_pcs_get_state(struct phylink_config *config,
-				      struct phylink_link_state *state)
-{
-	struct net_device *ndev = to_net_dev(config->dev);
-	struct axienet_local *lp = netdev_priv(ndev);
-	u32 emmc_reg, fcc_reg;
-
-	state->interface = lp->phy_mode;
-
-	emmc_reg = axienet_ior(lp, XAE_EMMC_OFFSET);
-	if (emmc_reg & XAE_EMMC_LINKSPD_1000)
-		state->speed = SPEED_1000;
-	else if (emmc_reg & XAE_EMMC_LINKSPD_100)
-		state->speed = SPEED_100;
-	else
-		state->speed = SPEED_10;
-
-	state->pause = 0;
-	fcc_reg = axienet_ior(lp, XAE_FCC_OFFSET);
-	if (fcc_reg & XAE_FCC_FCTX_MASK)
-		state->pause |= MLO_PAUSE_TX;
-	if (fcc_reg & XAE_FCC_FCRX_MASK)
-		state->pause |= MLO_PAUSE_RX;
-
-	state->an_complete = 0;
-	state->duplex = 1;
-}
-
-static void axienet_mac_an_restart(struct phylink_config *config)
-{
-	/* Unsupported, do nothing */
-}
-
-static void axienet_mac_config(struct phylink_config *config, unsigned int mode,
-			       const struct phylink_link_state *state)
-{
-	/* nothing meaningful to do */
-}
-
-static void axienet_mac_link_down(struct phylink_config *config,
-				  unsigned int mode,
-				  phy_interface_t interface)
-{
-	/* nothing meaningful to do */
-}
-
-static void axienet_mac_link_up(struct phylink_config *config,
-				struct phy_device *phy,
-				unsigned int mode, phy_interface_t interface,
-				int speed, int duplex,
-				bool tx_pause, bool rx_pause)
-{
-	struct net_device *ndev = to_net_dev(config->dev);
-	struct axienet_local *lp = netdev_priv(ndev);
-	u32 emmc_reg, fcc_reg;
-
-	emmc_reg = axienet_ior(lp, XAE_EMMC_OFFSET);
-	emmc_reg &= ~XAE_EMMC_LINKSPEED_MASK;
-
-	switch (speed) {
-	case SPEED_2500:
-		emmc_reg |= XAE_EMMC_LINKSPD_2500;
-		break;
-	case SPEED_1000:
-		emmc_reg |= XAE_EMMC_LINKSPD_1000;
-		break;
-	case SPEED_100:
-		emmc_reg |= XAE_EMMC_LINKSPD_100;
-		break;
-	case SPEED_10:
-		emmc_reg |= XAE_EMMC_LINKSPD_10;
-		break;
-	default:
-		dev_err(&ndev->dev,
-			"Speed other than 10, 100 or 1Gbps is not supported\n");
-		break;
-	}
-
-	axienet_iow(lp, XAE_EMMC_OFFSET, emmc_reg);
-
-	fcc_reg = axienet_ior(lp, XAE_FCC_OFFSET);
-	if (tx_pause)
-		fcc_reg |= XAE_FCC_FCTX_MASK;
-	else
-		fcc_reg &= ~XAE_FCC_FCTX_MASK;
-	if (rx_pause)
-		fcc_reg |= XAE_FCC_FCRX_MASK;
-	else
-		fcc_reg &= ~XAE_FCC_FCRX_MASK;
-	axienet_iow(lp, XAE_FCC_OFFSET, fcc_reg);
-}
-
-static const struct phylink_mac_ops axienet_phylink_ops = {
-	.validate = axienet_validate,
-	.mac_pcs_get_state = axienet_mac_pcs_get_state,
-	.mac_an_restart = axienet_mac_an_restart,
-	.mac_config = axienet_mac_config,
-	.mac_link_down = axienet_mac_link_down,
-	.mac_link_up = axienet_mac_link_up,
-};
-
 static int axienet_clk_init(struct platform_device *pdev,
 			    struct clk **axi_aclk, struct clk **axis_clk,
 			    struct clk **ref_clk, struct clk **tmpclk)
@@ -3003,37 +2935,12 @@ static int axienet_probe(struct platform_device *pdev)
 	 */
 	of_property_read_u32(pdev->dev.of_node, "xlnx,rxmem", &lp->rxmem);
 
-	/* Start with the proprietary, and broken phy_type */
-	ret = of_property_read_u32(pdev->dev.of_node, "xlnx,phy-type", &value);
-	if (!ret) {
-		switch (value) {
-		case XAE_PHY_TYPE_MII:
-			lp->phy_mode = PHY_INTERFACE_MODE_MII;
-			break;
-		case XAE_PHY_TYPE_GMII:
-			lp->phy_mode = PHY_INTERFACE_MODE_GMII;
-			break;
-		case XAE_PHY_TYPE_RGMII_2_0:
-			lp->phy_mode = PHY_INTERFACE_MODE_RGMII_ID;
-			break;
-		case XAE_PHY_TYPE_SGMII:
-			lp->phy_mode = PHY_INTERFACE_MODE_SGMII;
-			break;
-		case XAE_PHY_TYPE_1000BASE_X:
-			lp->phy_mode = PHY_INTERFACE_MODE_1000BASEX;
-			break;
-		case XXE_PHY_TYPE_USXGMII:
-			lp->phy_mode = PHY_INTERFACE_MODE_USXGMII;
-			break;
-		default:
-			/* Don't error out as phy-type is an optional property */
-			break;
-		}
-	} else {
-		ret = of_get_phy_mode(pdev->dev.of_node, &lp->phy_mode);
-		if (ret)
-			goto free_netdev;
-	}
+	/* The phy_mode is optional but when it is not specified it should not
+	 *  be a value that alters the driver behavior so set it to an invalid
+	 *  value as the default.
+	 */
+	lp->phy_mode = ~0;
+	of_property_read_u32(pdev->dev.of_node, "xlnx,phy-type", &lp->phy_mode);
 
 	/* Set default USXGMII rate */
 	lp->usxgmii_rate = SPEED_1000;
@@ -3154,6 +3061,13 @@ static int axienet_probe(struct platform_device *pdev)
 	lp->coalesce_count_rx = XAXIDMA_DFT_RX_THRESHOLD;
 	lp->coalesce_count_tx = XAXIDMA_DFT_TX_THRESHOLD;
 
+	ret = of_get_phy_mode(pdev->dev.of_node, &lp->phy_mode);
+	if (ret < 0)
+		dev_warn(&pdev->dev, "couldn't find phy i/f\n");
+	lp->phy_interface = ret;
+	if (lp->phy_mode == XAE_PHY_TYPE_1000BASE_X)
+		lp->phy_flags = XAE_PHY_TYPE_1000BASE_X;
+
 	lp->phy_node = of_parse_phandle(pdev->dev.of_node, "phy-handle", 0);
 	if (lp->phy_node) {
 		lp->clk = devm_clk_get(&pdev->dev, NULL);
@@ -3174,18 +3088,6 @@ static int axienet_probe(struct platform_device *pdev)
 		if (ret)
 			dev_warn(&pdev->dev,
 				 "error registering MDIO bus: %d\n", ret);
-
-		lp->phylink_config.dev = &ndev->dev;
-		lp->phylink_config.type = PHYLINK_NETDEV;
-
-		lp->phylink = phylink_create(&lp->phylink_config, pdev->dev.fwnode,
-					     lp->phy_mode,
-					     &axienet_phylink_ops);
-		if (IS_ERR(lp->phylink)) {
-			ret = PTR_ERR(lp->phylink);
-			dev_err(&pdev->dev, "phylink_create error (%i)\n", ret);
-			goto free_netdev;
-		}
 	}
 
 #ifdef CONFIG_AXIENET_HAS_MCDMA
@@ -3225,9 +3127,6 @@ static int axienet_remove(struct platform_device *pdev)
 	unregister_netdev(ndev);
 	axienet_clk_disable(pdev);
 
-	if (lp->phylink)
-		phylink_destroy(lp->phylink);
-
 	if (lp->mii_bus)
 		axienet_mdio_teardown(lp);
 
--- drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -1309,6 +1390,7 @@ static int axienet_recv(struct net_device *ndev, int budget,
 
 		skb_put(skb, length);
 #ifdef CONFIG_XILINX_AXI_EMAC_HWTSTAMP
+	if (!lp->is_tsn) {
 		if ((lp->tstamp_config.rx_filter == HWTSTAMP_FILTER_ALL ||
 			lp->eth_hasptp) && (lp->axienet_config->mactype != XAXIENET_10G_25G)) {
 			u32 sec, nsec;
@@ -1337,6 +1419,7 @@ static int axienet_recv(struct net_device *ndev, int budget,
 		} else if (lp->axienet_config->mactype == XAXIENET_10G_25G) {
 			axienet_rx_hwtstamp(lp, skb);
 		}
+	}
 #endif
 		skb->protocol = eth_type_trans(skb, ndev);
 		/*skb_checksum_none_assert(skb);*/
@@ -2950,9 +3109,17 @@ static int axienet_probe(struct platform_device *pdev)
 	lp->options = XAE_OPTION_DEFAULTS;
 	lp->num_tx_queues = num_queues;
 	lp->num_rx_queues = num_queues;
+	lp->is_tsn = is_tsn;
 	lp->rx_bd_num = RX_BD_NUM_DEFAULT;
 	lp->tx_bd_num = TX_BD_NUM_DEFAULT;
 
+#ifdef CONFIG_XILINX_TSN
+	ret = of_property_read_u16(pdev->dev.of_node, "xlnx,num-tc",
+				   &lp->num_tc);
+	if (ret || (lp->num_tc != 2 && lp->num_tc != 3))
+		lp->num_tc = XAE_MAX_TSN_TC;
+#endif
+
 	/* Map device registers */
 	ethres = platform_get_resource(pdev, IORESOURCE_MEM, 0);
 	lp->regs = devm_ioremap_resource(&pdev->dev, ethres);
@@ -3054,58 +3229,64 @@ static int axienet_probe(struct platform_device *pdev)
 		lp->eth_irq = platform_get_irq(pdev, 0);
 
 #ifdef CONFIG_XILINX_AXI_EMAC_HWTSTAMP
-	struct resource txtsres, rxtsres;
-
-	/* Find AXI Stream FIFO */
-	np = of_parse_phandle(pdev->dev.of_node, "axififo-connected", 0);
-	if (IS_ERR(np)) {
-		dev_err(&pdev->dev, "could not find TX Timestamp FIFO\n");
-		ret = PTR_ERR(np);
-		goto free_netdev;
-	}
-
-	ret = of_address_to_resource(np, 0, &txtsres);
-	if (ret) {
-		dev_err(&pdev->dev, "unable to get Tx Timestamp resource\n");
-		goto free_netdev;
-	}
+	if (!lp->is_tsn) {
+		struct resource txtsres, rxtsres;
 
-	lp->tx_ts_regs = devm_ioremap_resource(&pdev->dev, &txtsres);
-	if (IS_ERR(lp->tx_ts_regs)) {
-		dev_err(&pdev->dev, "could not map Tx Timestamp regs\n");
-		ret = PTR_ERR(lp->tx_ts_regs);
-		goto free_netdev;
-	}
-
-	if (lp->axienet_config->mactype == XAXIENET_10G_25G) {
-		np = of_parse_phandle(pdev->dev.of_node, "xlnx,rxtsfifo",
+		/* Find AXI Stream FIFO */
+		np = of_parse_phandle(pdev->dev.of_node, "axififo-connected",
 				      0);
 		if (IS_ERR(np)) {
-			dev_err(&pdev->dev,
-				"couldn't find rx-timestamp FIFO\n");
+			dev_err(&pdev->dev, "could not find TX Timestamp FIFO\n");
 			ret = PTR_ERR(np);
 			goto free_netdev;
 		}
 
-		ret = of_address_to_resource(np, 0, &rxtsres);
+		ret = of_address_to_resource(np, 0, &txtsres);
 		if (ret) {
 			dev_err(&pdev->dev,
-				"unable to get rx-timestamp resource\n");
+				"unable to get Tx Timestamp resource\n");
 			goto free_netdev;
 		}
 
-		lp->rx_ts_regs = devm_ioremap_resource(&pdev->dev, &rxtsres);
-		if (IS_ERR(lp->rx_ts_regs)) {
-			dev_err(&pdev->dev, "couldn't map rx-timestamp regs\n");
-			ret = PTR_ERR(lp->rx_ts_regs);
+		lp->tx_ts_regs = devm_ioremap_resource(&pdev->dev, &txtsres);
+		if (IS_ERR(lp->tx_ts_regs)) {
+			dev_err(&pdev->dev, "could not map Tx Timestamp regs\n");
+			ret = PTR_ERR(lp->tx_ts_regs);
 			goto free_netdev;
 		}
-		lp->tx_ptpheader = devm_kzalloc(&pdev->dev,
+
+		if (lp->axienet_config->mactype == XAXIENET_10G_25G) {
+			np = of_parse_phandle(pdev->dev.of_node,
+					      "xlnx,rxtsfifo", 0);
+			if (IS_ERR(np)) {
+				dev_err(&pdev->dev,
+					"couldn't find rx-timestamp FIFO\n");
+				ret = PTR_ERR(np);
+				goto free_netdev;
+			}
+
+			ret = of_address_to_resource(np, 0, &rxtsres);
+			if (ret) {
+				dev_err(&pdev->dev,
+					"unable to get rx-timestamp resource\n");
+				goto free_netdev;
+			}
+
+			lp->rx_ts_regs = devm_ioremap_resource(&pdev->dev,
+								&rxtsres);
+			if (IS_ERR(lp->rx_ts_regs)) {
+				dev_err(&pdev->dev,
+					"couldn't map rx-timestamp regs\n");
+				ret = PTR_ERR(lp->rx_ts_regs);
+				goto free_netdev;
+			}
+			lp->tx_ptpheader = devm_kzalloc(&pdev->dev,
 						XXVENET_TS_HEADER_LEN,
 						GFP_KERNEL);
-	}
+		}
 
-	of_node_put(np);
+		of_node_put(np);
+	}
 #endif
 	if (!slave) {
 #ifdef CONFIG_AXIENET_HAS_MCDMA
--- drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -54,7 +54,7 @@
 #endif
 /* Descriptors defines for Tx and Rx DMA */
 #define TX_BD_NUM_DEFAULT		64
-#define RX_BD_NUM_DEFAULT		1024
+#define RX_BD_NUM_DEFAULT		128
 #define TX_BD_NUM_MAX			4096
 #define RX_BD_NUM_MAX			4096
 
--- drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -1023,8 +1243,6 @@ void axienet_start_xmit_done(struct net_device *ndev,
 
 	ndev->stats.tx_packets += packets;
 	ndev->stats.tx_bytes += size;
-	q->tx_packets += packets;
-	q->tx_bytes += size;
 
 	/* Matches barrier in axienet_start_xmit */
 	smp_mb();
@@ -1198,7 +1416,8 @@ static int axienet_skb_tstsmp(struct sk_buff **__skb, struct axienet_dma_q *q,
 	if ((((lp->tstamp_config.tx_type == HWTSTAMP_TX_ONESTEP_SYNC) ||
 	      (lp->tstamp_config.tx_type == HWTSTAMP_TX_ON)) ||
 	       lp->eth_hasptp) && (lp->axienet_config->mactype !=
-	       XAXIENET_10G_25G)) {
+	       XAXIENET_10G_25G) &&
+	       (lp->axienet_config->mactype != XAXIENET_MRMAC)) {
 		u8 *tmp;
 		struct sk_buff *new_skb;
 
@@ -1401,7 +1621,6 @@ static int axienet_queue_xmit(struct sk_buff *skb,
 
 		if (++q->tx_bd_tail >= lp->tx_bd_num)
 			q->tx_bd_tail = 0;
-
 #ifdef CONFIG_AXIENET_HAS_MCDMA
 		cur_p = &q->txq_bd_v[q->tx_bd_tail];
 #else
@@ -1531,7 +1750,9 @@ static int axienet_recv(struct net_device *ndev, int budget,
 #ifdef CONFIG_XILINX_AXI_EMAC_HWTSTAMP
 	if (!lp->is_tsn) {
 		if ((lp->tstamp_config.rx_filter == HWTSTAMP_FILTER_ALL ||
-			lp->eth_hasptp) && (lp->axienet_config->mactype != XAXIENET_10G_25G)) {
+			lp->eth_hasptp) &&
+			(lp->axienet_config->mactype != XAXIENET_10G_25G) &&
+			(lp->axienet_config->mactype != XAXIENET_MRMAC)) {
 			u32 sec, nsec;
 			u64 time64;
 			struct skb_shared_hwtstamps *shhwtstamps;
@@ -3298,12 +3541,16 @@ static int axienet_probe(struct platform_device *pdev)
 	 */
 	lp->phy_mode = ~0;
 	of_property_read_u32(pdev->dev.of_node, "xlnx,phy-type", &lp->phy_mode);
-
 	/* Set default USXGMII rate */
 	lp->usxgmii_rate = SPEED_1000;
 	of_property_read_u32(pdev->dev.of_node, "xlnx,usxgmii-rate",
 			     &lp->usxgmii_rate);
 
+	/* Set default MRMAC rate */
+	lp->mrmac_rate = SPEED_10000;
+	of_property_read_u32(pdev->dev.of_node, "xlnx,mrmac-rate",
+			     &lp->mrmac_rate);
+
 	lp->eth_hasnobuf = of_property_read_bool(pdev->dev.of_node,
 						 "xlnx,eth-hasnobuf");
 	lp->eth_hasptp = of_property_read_bool(pdev->dev.of_node,
--- drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -1571,7 +1587,8 @@ static int axienet_recv(struct net_device *ndev, int budget,
 			time64 = sec * NS_PER_SEC + nsec;
 			shhwtstamps = skb_hwtstamps(skb);
 			shhwtstamps->hwtstamp = ns_to_ktime(time64);
-		} else if (lp->axienet_config->mactype == XAXIENET_10G_25G) {
+		} else if (lp->axienet_config->mactype == XAXIENET_10G_25G ||
+			   lp->axienet_config->mactype == XAXIENET_MRMAC) {
 			axienet_rx_hwtstamp(lp, skb);
 		}
 	}
@@ -3441,7 +3470,8 @@ static int axienet_probe(struct platform_device *pdev)
 			goto free_netdev;
 		}
 
-		if (lp->axienet_config->mactype == XAXIENET_10G_25G) {
+		if (lp->axienet_config->mactype == XAXIENET_10G_25G ||
+		    lp->axienet_config->mactype == XAXIENET_MRMAC) {
 			np = of_parse_phandle(pdev->dev.of_node,
 					      "xlnx,rxtsfifo", 0);
 			if (IS_ERR(np)) {
--- drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -1094,10 +1094,11 @@ static inline int axienet_check_tx_bd_space(struct axienet_dma_q *q,
  * @buf:	Pointer to the buf to copy timestamp header
  * @msg_type:	PTP message type
  *
- * Return:	None.
+ * Return: 0, on success
+ *	    NETDEV_TX_BUSY, if timestamp FIFO has no vacancy
  */
-static void axienet_create_tsheader(u8 *buf, u8 msg_type,
-				    struct axienet_dma_q *q)
+static int axienet_create_tsheader(u8 *buf, u8 msg_type,
+				   struct axienet_dma_q *q)
 {
 	struct axienet_local *lp = q->lp;
 #ifdef CONFIG_AXIENET_HAS_MCDMA
@@ -3489,6 +3506,7 @@ static int axienet_probe(struct platform_device *pdev)
 			lp->tx_ptpheader = devm_kzalloc(&pdev->dev,
 						XXVENET_TS_HEADER_LEN,
 						GFP_KERNEL);
+			spin_lock_init(&lp->ptp_tx_lock);
 		}
 
 		of_node_put(np);
--- drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -3454,7 +3412,15 @@ static int axienet_probe(struct platform_device *pdev)
 		of_node_put(np);
 	}
 #endif
-	if (!slave) {
+
+#ifdef CONFIG_XILINX_TSN
+	if (lp->is_tsn)
+		ret = axienet_tsn_probe(pdev, lp, ndev);
+#ifdef CONFIG_AXIENET_HAS_MCDMA
+		ret = axienet_mcdma_probe(pdev, lp, ndev);
+#endif
+#endif
+	if (!lp->is_tsn) {
 #ifdef CONFIG_AXIENET_HAS_MCDMA
 		ret = axienet_mcdma_probe(pdev, lp, ndev);
 #else
--- drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -3458,9 +3458,6 @@ static int axienet_probe(struct platform_device *pdev)
 #ifdef CONFIG_XILINX_TSN
 	if (lp->is_tsn)
 		ret = axienet_tsn_probe(pdev, lp, ndev);
-#ifdef CONFIG_AXIENET_HAS_MCDMA
-		ret = axienet_mcdma_probe(pdev, lp, ndev);
-#endif
 #endif
 	if (!lp->is_tsn) {
 #ifdef CONFIG_AXIENET_HAS_MCDMA
--- drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -1547,8 +1547,30 @@ static int axienet_recv(struct net_device *ndev, int budget,
 			skb->csum = be32_to_cpu(cur_p->app3 & 0xFFFF);
 			skb->ip_summed = CHECKSUM_COMPLETE;
 		}
+#ifdef CONFIG_XILINX_TSN
+		if (unlikely(q->flags & MCDMA_MGMT_CHAN)) {
+			struct net_device *ndev = NULL;
+
+			/* received packet on mgmt channel */
+			if (q->flags & MCDMA_MGMT_CHAN_PORT0)
+				ndev = lp->slaves[0];
+			else if (q->flags & MCDMA_MGMT_CHAN_PORT1)
+				ndev = lp->slaves[1];
+
+			/* send to one of the front panel port */
+			if (ndev && netif_running(ndev)) {
+				skb->dev = ndev;
+				netif_receive_skb(skb);
+			} else {
+				kfree(skb); /* dont send up the stack */
+			}
+		} else {
+			netif_receive_skb(skb); /* send on normal data path */
+		}
+#else
 
 		netif_receive_skb(skb);
+#endif
 
 		size += length;
 		packets++;
--- drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -3259,7 +3259,7 @@ static int axienet_probe(struct platform_device *pdev)
 	 *  be a value that alters the driver behavior so set it to an invalid
 	 *  value as the default.
 	 */
-	lp->phy_mode = ~0;
+	lp->phy_mode = PHY_INTERFACE_MODE_NA;
 	of_property_read_u32(pdev->dev.of_node, "xlnx,phy-type", &lp->phy_mode);
 	/* Set default USXGMII rate */
 	lp->usxgmii_rate = SPEED_1000;
--- drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -513,7 +513,6 @@ static inline int axienet_mrmac_gt_reset(struct net_device *ndev)
 void __axienet_device_reset(struct axienet_dma_q *q)
 {
 	u32 timeout;
-
 	/* Reset Axi DMA. This would reset Axi Ethernet core as well. The reset
 	 * process of Axi DMA takes a while to complete as all pending
 	 * commands/transfers will be flushed or completed during this
@@ -532,7 +531,6 @@ void __axienet_device_reset(struct axienet_dma_q *q)
 			break;
 		}
 	}
-
 }
 
 /**
@@ -1284,6 +1201,7 @@ int axienet_queue_xmit(struct sk_buff *skb,
 
 		if (++q->tx_bd_tail >= lp->tx_bd_num)
 			q->tx_bd_tail = 0;
+
 #ifdef CONFIG_AXIENET_HAS_MCDMA
 		cur_p = &q->txq_bd_v[q->tx_bd_tail];
 #else
@@ -3152,6 +3037,7 @@ static int axienet_probe(struct platform_device *pdev)
 	 */
 	lp->phy_mode = PHY_INTERFACE_MODE_NA;
 	of_property_read_u32(pdev->dev.of_node, "xlnx,phy-type", &lp->phy_mode);
+
 	/* Set default USXGMII rate */
 	lp->usxgmii_rate = SPEED_1000;
 	of_property_read_u32(pdev->dev.of_node, "xlnx,usxgmii-rate",
--- drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -3308,9 +3315,10 @@ static int axienet_probe(struct platform_device *pdev)
 				ret = PTR_ERR(lp->rx_ts_regs);
 				goto free_netdev;
 			}
+
 			lp->tx_ptpheader = devm_kzalloc(&pdev->dev,
-						XXVENET_TS_HEADER_LEN,
-						GFP_KERNEL);
+							lp->axienet_config->ts_header_len,
+							GFP_KERNEL);
 			spin_lock_init(&lp->ptp_tx_lock);
 		}
 
--- drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -1092,6 +1111,19 @@ static int axienet_create_tsheader(u8 *buf, u8 msg_type,
 #endif
 
 #ifdef CONFIG_XILINX_AXI_EMAC_HWTSTAMP
+static inline u8 ptp_os(struct sk_buff *skb, struct axienet_local *lp)
+{
+	u8 *msg_type;
+	int packet_flags = 0;
+
+	/* Identify and return packets requiring PTP one step TS */
+	msg_type = (u8 *)skb->data + PTP_TYPE_OFFSET;
+	if ((*msg_type & 0xF) == PTP_TYPE_SYNC)
+		packet_flags = MSG_TYPE_SYNC_FLAG;
+
+	return packet_flags;
+}
+
 static int axienet_skb_tstsmp(struct sk_buff **__skb, struct axienet_dma_q *q,
 			      struct net_device *ndev)
 {
--- drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -1135,6 +1169,9 @@ static inline u8 ptp_os(struct sk_buff *skb, struct axienet_local *lp)
 	msg_type = (u8 *)skb->data + PTP_TYPE_OFFSET;
 	if ((*msg_type & 0xF) == PTP_TYPE_SYNC)
 		packet_flags = MSG_TYPE_SYNC_FLAG;
+	else if (((*msg_type & 0xF) == PTP_TYPE_PDELAY_RESP) &&
+		 (lp->tstamp_config.tx_type == HWTSTAMP_TX_ONESTEP_P2P))
+		packet_flags = MSG_TYPE_PDELAY_RESP_FLAG;
 
 	return packet_flags;
 }
--- drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -3344,7 +3344,9 @@ static int axienet_probe(struct platform_device *pdev)
 	 *  value as the default.
 	 */
 	lp->phy_mode = PHY_INTERFACE_MODE_NA;
-	of_property_read_u32(pdev->dev.of_node, "xlnx,phy-type", &lp->phy_mode);
+	ret = of_property_read_u32(pdev->dev.of_node, "xlnx,phy-type", &lp->phy_mode);
+	if (!ret)
+		netdev_warn(ndev, "xlnx,phy-type is deprecated, Please upgrade your device tree to use phy-mode");
 
 	/* Set default USXGMII rate */
 	lp->usxgmii_rate = SPEED_1000;
@@ -3564,7 +3566,7 @@ static int axienet_probe(struct platform_device *pdev)
 	if (ret < 0)
 		dev_warn(&pdev->dev, "couldn't find phy i/f\n");
 	lp->phy_interface = ret;
-	if (lp->phy_mode == XAE_PHY_TYPE_1000BASE_X)
+	if (lp->phy_mode == PHY_INTERFACE_MODE_1000BASEX)
 		lp->phy_flags = XAE_PHY_TYPE_1000BASE_X;
 
 	lp->phy_node = of_parse_phandle(pdev->dev.of_node, "phy-handle", 0);
--- drivers/net/ethernet/xilinx/xilinx_axienet_main.c
+++ drivers/net/ethernet/xilinx/xilinx_axienet_main.c
@@ -3576,7 +3576,6 @@ static int axienet_probe(struct platform_device *pdev)
 	ret = of_get_phy_mode(pdev->dev.of_node, &lp->phy_mode);
 	if (ret < 0)
 		dev_warn(&pdev->dev, "couldn't find phy i/f\n");
-	lp->phy_interface = ret;
 	if (lp->phy_mode == PHY_INTERFACE_MODE_1000BASEX)
 		lp->phy_flags = XAE_PHY_TYPE_1000BASE_X;
 
